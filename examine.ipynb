{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7721c480",
   "metadata": {},
   "outputs": [],
   "source": [
    "from helpers.dataset import get_dataset\n",
    "from src.framework import construct_cim\n",
    "\n",
    "from helpers.dataset import MUFFIN_TASK, CUSTOM_TASKS, CROSS_TASK_TASKS\n",
    "\n",
    "# task = MUFFIN_TASK\n",
    "task = CUSTOM_TASKS[14]\n",
    "\n",
    "results = construct_cim(task, get_dataset(task), \"segmentation_v1\")\n",
    "\n",
    "dataset = results['labeled_dataset']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5a31d5b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import sys\n",
    "import json\n",
    "\n",
    "from helpers.dataset import IMPORTANT_TYPES_FINE, IMPORTANT_TYPE_DESCRIPTIONS_FINE\n",
    "\n",
    "def display_tutorial_contexts(tutorial, include_keys=None, include_content_types=None):\n",
    "    \"\"\"\n",
    "    print in markdown table format where columns are keys and rows are values\n",
    "    \"\"\"\n",
    "    columns = defaultdict(list)\n",
    "    \n",
    "    columns['info_type'] = []\n",
    "    columns['content'] = []\n",
    "\n",
    "    for piece in tutorial['pieces']:\n",
    "        if include_content_types is not None and piece['content_type'] not in include_content_types:\n",
    "            continue\n",
    "        columns['info_type'].append(piece['content_type'])\n",
    "        if 'content' in columns:\n",
    "            columns['content'].append(piece['content'])\n",
    "        for key, value in piece['labels'].items():\n",
    "            if include_keys is None or key in include_keys:\n",
    "                columns[key].append(value[-1])\n",
    "    \n",
    "    markdown_table = \"| \" + \" | \".join(columns.keys()) + \" |\\n\"\n",
    "    markdown_table += \"| \" + \" | \".join([\"---\"] * len(columns)) + \" |\\n\"\n",
    "    for i in range(len(columns[list(columns.keys())[0]])):\n",
    "        markdown_table += \"| \" + \" | \".join([columns[key][i] for key in columns.keys()]) + \" |\\n\"\n",
    "    markdown_table += \"| \" + \" | \".join([\"---\"] * len(columns)) + \" |\\n\"\n",
    "    print(markdown_table)\n",
    "\n",
    "def display_units(dataset, include_keys=None, include_content_types=None):\n",
    "    import matplotlib.pyplot as plt\n",
    "    units = defaultdict(list)\n",
    "    for tutorial in dataset:\n",
    "        for piece in tutorial['pieces']:\n",
    "            if include_content_types is not None and piece['content_type'] not in include_content_types:\n",
    "                continue\n",
    "            units[piece['unit_id']].append(piece)\n",
    "    \n",
    "    ### sort in descending order of number of pieces\n",
    "    units = sorted(units.items(), key=lambda x: len(x[1]), reverse=True)\n",
    "\n",
    "    ### show distribution of pieces across units (#of pieces vs #of units)\n",
    "    lengths = defaultdict(int)\n",
    "    for _, pieces in units:\n",
    "        lengths[len(pieces)] += 1\n",
    "    \n",
    "    print(json.dumps(lengths, indent=4))\n",
    "\n",
    "    # for unit_id, pieces in units:\n",
    "    #     print(f\"Unit {unit_id} ({len(pieces)} pieces) \")\n",
    "    #     for piece in pieces:\n",
    "    #         print(f\"  - {piece['content_type']}: {piece['content']}\")\n",
    "    #     print()\n",
    "\n",
    "def display_type_distribution(dataset):\n",
    "    per_type = defaultdict(int)\n",
    "\n",
    "    for tutorial in dataset:\n",
    "        for piece in tutorial['pieces']:\n",
    "            if piece['content_type'] in IMPORTANT_TYPES_FINE:\n",
    "                per_type[piece['content_type']] += 1\n",
    "    \n",
    "    ### sort in descending order of number of pieces\n",
    "    per_type = sorted(per_type.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    print(json.dumps(per_type, indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "34057036",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"11\": 1,\n",
      "    \"3\": 1,\n",
      "    \"2\": 22,\n",
      "    \"1\": 1012\n",
      "}\n",
      "{\n",
      "    \"11\": 1,\n",
      "    \"3\": 1,\n",
      "    \"2\": 17,\n",
      "    \"1\": 855\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# for i in range(len(dataset)):\n",
    "#     display_tutorial_contexts(dataset[i], ['context_stage'])\n",
    "display_units(dataset, include_keys=['context_stage'])\n",
    "display_units(dataset, include_keys=['context_stage'], \n",
    "include_content_types=IMPORTANT_TYPES_FINE)\n",
    "# display_type_distribution(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a19808c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "starlab-video-analysis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
